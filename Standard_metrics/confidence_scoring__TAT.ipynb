{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Confidence Scoring and Flagging:**"
      ],
      "metadata": {
        "id": "buTxPvK38Vj6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDNxIFf88EYR",
        "outputId": "7d75b6d4-b597-4f54-9b39-aff7be28e81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flagged segments for review:\n",
            "{'text': 'metoprolol', 'confidence': 0.62}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "asr_output = [\n",
        "    {\"text\": \"Patient has hypertension\", \"confidence\": 0.94},\n",
        "    {\"text\": \"and is prescribed\", \"confidence\": 0.81},\n",
        "    {\"text\": \"metoprolol\", \"confidence\": 0.62},  # low confidence\n",
        "    {\"text\": \"once daily\", \"confidence\": 0.90}\n",
        "]\n",
        "\n",
        "THRESHOLD = 0.75\n",
        "\n",
        "flagged_segments = []\n",
        "\n",
        "for segment in asr_output:\n",
        "    if segment[\"confidence\"] < THRESHOLD:\n",
        "        flagged_segments.append(segment)\n",
        "\n",
        "print(\"Flagged segments for review:\")\n",
        "for seg in flagged_segments:\n",
        "    print(seg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimal Threshold:**"
      ],
      "metadata": {
        "id": "0DQnUC_V-itG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Example confidence scores and ground truth\n",
        "# 1 = correct transcription, 0 = incorrect\n",
        "confidence_scores = np.array([0.95, 0.88, 0.72, 0.65, 0.55, 0.40])\n",
        "ground_truth = np.array([1, 1, 1, 0, 0, 0])\n",
        "\n",
        "thresholds = np.arange(0.4, 0.95, 0.05)\n",
        "best_threshold = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    predictions = (confidence_scores >= t).astype(int)\n",
        "    f1 = f1_score(ground_truth, predictions)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best F1 Score:\", best_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfbn7ugB-bGY",
        "outputId": "aa51a8cd-2bec-4d01-8e96-28ace55bdc6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.7\n",
            "Best F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confidence Calibration:**"
      ],
      "metadata": {
        "id": "98uIctRlD3Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# Raw confidence scores from ASR/NLP system\n",
        "raw_confidence = np.array([0.95, 0.88, 0.72, 0.65, 0.55, 0.40]).reshape(-1, 1)\n",
        "\n",
        "# Ground truth: 1 = correct, 0 = incorrect\n",
        "labels = np.array([1, 1, 1, 0, 0, 0])\n",
        "\n",
        "# Train Platt scaling model\n",
        "platt = LogisticRegression()\n",
        "platt.fit(raw_confidence, labels)\n",
        "\n",
        "# Calibrated confidence scores\n",
        "calibrated_confidence = platt.predict_proba(raw_confidence)[:, 1]\n",
        "\n",
        "print(\"Raw confidence:\", raw_confidence.flatten())\n",
        "print(\"Calibrated confidence:\", calibrated_confidence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rlXB3Up-ulY",
        "outputId": "7ff680a5-683a-4e43-d4d5-115203e8de30"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw confidence: [0.95 0.88 0.72 0.65 0.55 0.4 ]\n",
            "Calibrated confidence: [0.52911517 0.52123685 0.50319585 0.49529752 0.48401924 0.46713587]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizing FP/FN Trade-off:**"
      ],
      "metadata": {
        "id": "8YqophrGEtX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Confidence scores from ASR/NLP system\n",
        "confidence_scores = np.array([0.95, 0.88, 0.72, 0.65, 0.55, 0.40])\n",
        "\n",
        "# Ground truth: 1 = correct, 0 = incorrect\n",
        "ground_truth = np.array([1, 1, 1, 0, 0, 0])\n",
        "\n",
        "def evaluate_threshold(threshold):\n",
        "    # Predict \"accept\" (1) if confidence >= threshold, else \"flag\" (0)\n",
        "    predictions = (confidence_scores >= threshold).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(ground_truth, predictions).ravel()\n",
        "    return {\"threshold\": threshold, \"FP\": fp, \"FN\": fn, \"TP\": tp, \"TN\": tn}\n",
        "\n",
        "# Test multiple thresholds\n",
        "thresholds = [0.5, 0.7, 0.85]\n",
        "results = [evaluate_threshold(t) for t in thresholds]\n",
        "\n",
        "for r in results:\n",
        "    print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKYTngbVElz8",
        "outputId": "6778f839-131f-4293-adc2-cead50022362"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'threshold': 0.5, 'FP': np.int64(2), 'FN': np.int64(0), 'TP': np.int64(3), 'TN': np.int64(1)}\n",
            "{'threshold': 0.7, 'FP': np.int64(0), 'FN': np.int64(0), 'TP': np.int64(3), 'TN': np.int64(3)}\n",
            "{'threshold': 0.85, 'FP': np.int64(0), 'FN': np.int64(1), 'TP': np.int64(2), 'TN': np.int64(3)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Real/Batch time TAT:**"
      ],
      "metadata": {
        "id": "B2nS1zw2GPdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def transcribe(audio_length_seconds, mode=\"batch\"):\n",
        "    start = time.time()\n",
        "\n",
        "    if mode == \"realtime\":\n",
        "        time.sleep(audio_length_seconds * 0.1)  # simulate streaming delay\n",
        "    else:\n",
        "        time.sleep(audio_length_seconds * 0.5)  # simulate batch processing\n",
        "\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n",
        "# Simulate 30-second audio\n",
        "print(\"Real-time TAT:\", transcribe(30, \"realtime\"), \"seconds\")\n",
        "print(\"Batch TAT:\", transcribe(30, \"batch\"), \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBljOPrFEyQH",
        "outputId": "6db420cf-bb8d-43ca-b3fd-5693b934d22b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-time TAT: 3.0035552978515625 seconds\n",
            "Batch TAT: 15.000099182128906 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Measuring Latency:**"
      ],
      "metadata": {
        "id": "y5NwG15lIZM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def simulate_transcription(latency_seconds):\n",
        "    start = time.time()\n",
        "    time.sleep(latency_seconds)\n",
        "    return time.time() - start\n",
        "\n",
        "print(\"Emergency use-case latency:\", simulate_transcription(1), \"seconds\")\n",
        "print(\"Batch documentation latency:\", simulate_transcription(10), \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFqmuBsIX45",
        "outputId": "f6c1c32b-3090-47c7-a831-1ccf36a3d68f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emergency use-case latency: 1.0000929832458496 seconds\n",
            "Batch documentation latency: 10.00217342376709 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accuracy-speed trade-off curve:**"
      ],
      "metadata": {
        "id": "amaJcJKtJz5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "def transcribe(mode=\"fast\"):\n",
        "    start = time.time()\n",
        "\n",
        "    if mode == \"fast\":\n",
        "        time.sleep(1)  # fast processing\n",
        "        accuracy = random.uniform(0.85, 0.90)\n",
        "    else:\n",
        "        time.sleep(3)  # slower, more accurate\n",
        "        accuracy = random.uniform(0.93, 0.97)\n",
        "\n",
        "    latency = time.time() - start\n",
        "    return latency, accuracy\n",
        "\n",
        "fast_latency, fast_accuracy = transcribe(\"fast\")\n",
        "slow_latency, slow_accuracy = transcribe(\"accurate\")\n",
        "\n",
        "print(\"Fast mode → Latency:\", fast_latency, \"Accuracy:\", fast_accuracy)\n",
        "print(\"Accurate mode → Latency:\", slow_latency, \"Accuracy:\", slow_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVFmF4CEJat9",
        "outputId": "dcc6cf38-7c32-42a8-a3cd-058c71bb908b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast mode → Latency: 1.0001413822174072 Accuracy: 0.8742763420123676\n",
            "Accurate mode → Latency: 3.0001702308654785 Accuracy: 0.9427962670556507\n"
          ]
        }
      ]
    }
  ]
}