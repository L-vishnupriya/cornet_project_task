# -*- coding: utf-8 -*-
"""Eva_tools imp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kb_2E_9TObgbSepr0UBoOpRPwP5XY9Pz

**Paired t-test on WER Scores:**
"""

from scipy.stats import ttest_rel

# Example WER scores for two ASR systems on the same files
wer_model_A = [0.29, 0.31, 0.28, 0.30, 0.27]
wer_model_B = [0.24, 0.26, 0.25, 0.27, 0.23]

# Paired t-test
t_stat, p_value = ttest_rel(wer_model_A, wer_model_B)

print("t-statistic:", t_stat)
print("p-value:", p_value)

if p_value < 0.05:
    print("Difference is statistically significant")
else:
    print("Difference is NOT statistically significant")

"""p < 0.05 - statistically significant improvement

p â‰¥ 0.05 - difference may be due to chance

**Continuous Monitoring Loop**
"""

import time

# Simulated production metrics stream
production_metrics = [
    {"wer": 0.22, "latency": 1.2},
    {"wer": 0.24, "latency": 1.3},
    {"wer": 0.35, "latency": 2.5},  # degradation
]

WER_THRESHOLD = 0.30
LATENCY_THRESHOLD = 2.0

for metric in production_metrics:
    if metric["wer"] > WER_THRESHOLD or metric["latency"] > LATENCY_THRESHOLD:
        print("Alert: Performance degradation detected", metric)
    else:
        print("System healthy", metric)
    time.sleep(1)

pip install jiwer

"""**Tool and Implementation:**

**ASR evaluation**
"""

from jiwer import wer

reference = "patient has diabetes and hypertension"
hypothesis = "patient has diabetes and high tension"

error_rate = wer(reference, hypothesis)
print("WER:", error_rate)

"""**Scispacy**"""

pip install spacy scispacy

pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz

import spacy
nlp = spacy.load("en_core_sci_sm")
doc = nlp("Patient prescribed insulin for diabetes")
print([(ent.text, ent.label_) for ent in doc.ents])

"""**stanza**"""

pip install stanza

import stanza
stanza.download("en")
nlp = stanza.Pipeline("en", processors="tokenize,ner")
doc = nlp("Patient has hypertension")
print([(ent.text, ent.type) for ent in doc.ents])

"""**Levenshtein Distance:**"""

def levenshtein(a, b):
    n, m = len(a), len(b)
    dp = [[0]*(m+1) for _ in range(n+1)]
    for i in range(n+1): dp[i][0] = i
    for j in range(m+1): dp[0][j] = j
    for i in range(1, n+1):
        for j in range(1, m+1):
            cost = 0 if a[i-1] == b[j-1] else 1
            dp[i][j] = min(
                dp[i-1][j] + 1,      # deletion
                dp[i][j-1] + 1,      # insertion
                dp[i-1][j-1] + cost  # substitution
            )
    return dp[n][m]

print(levenshtein("insulin", "insuline"))

"""**Alignment Output:**"""

from difflib import ndiff

ref = "patient prescribed insulin 10 units".split()
hyp = "patient prescribed insulin 100 units".split()

for d in ndiff(ref, hyp):
    if d.startswith(("- ", "+ ")):
        print(d)

"""**Error Distribution Bar Chart**"""

import matplotlib.pyplot as plt

error_counts = {
    "Substitution": 45,
    "Deletion": 30,
    "Insertion": 20
}

plt.bar(error_counts.keys(), error_counts.values())
plt.xlabel("Error Type")
plt.ylabel("Count")
plt.title("ASR Error Distribution")
plt.show()

"""**Confusion Matrix Visualization**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

true_labels = ["insulin", "insulin", "metformin", "aspirin"]
pred_labels = ["insulin", "metformin", "metformin", "asprin"]

labels = list(set(true_labels + pred_labels))
cm = confusion_matrix(true_labels, pred_labels, labels=labels)

sns.heatmap(cm, annot=True, xticklabels=labels, yticklabels=labels, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Word Confusion Matrix")
plt.show()

"""**Alignment-Based Error Highlighting**"""

from difflib import ndiff

ref = "patient prescribed insulin 10 units".split()
hyp = "patient prescribed insulin 100 units".split()

for d in ndiff(ref, hyp):
    print(d)